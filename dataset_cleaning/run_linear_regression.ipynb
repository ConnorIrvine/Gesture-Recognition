{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3877e8c1",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "This project is for making a linear regression model for joint angle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e316019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import resample, decimate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d769f41",
   "metadata": {},
   "source": [
    "The dataset needs to be restructured for linear regression.\n",
    "We don't need the gesture labels anymore, since our target is just joint angles.\n",
    "We need to window the joint angles too. For simplicity we will average the 200ms window of joint angle data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43368b",
   "metadata": {},
   "source": [
    "# Dataset export to get glove kinematic target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "209a31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Features (from SEED dataset)\n",
    "\"\"\"\n",
    "\n",
    "def MAV(data):\n",
    "    \"\"\"\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: MAV of the data\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(data), axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "def VAR(data):\n",
    "    \"\"\"\n",
    "    Variance\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Variance of the data\n",
    "    \"\"\"\n",
    "    return np.var(data, axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "def RMS(data):\n",
    "    \"\"\"\n",
    "    Root mean square\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: RMS per channel\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean(data**2, axis=1)).reshape((1, data.shape[0]))\n",
    "\n",
    "def zero_crossings(data):\n",
    "    \"\"\"\n",
    "    Number of zero crossings from each channel\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: number of zero crossings for each channel\n",
    "    \"\"\"\n",
    "    positive = data > 0\n",
    "    return np.sum(np.bitwise_xor(positive[:, 1:], positive[:, :-1]), axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "def avg_amplitude_change(data):\n",
    "    \"\"\"\n",
    "    https://www.sciencedirect.com/science/article/pii/S0957417412001200\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Average amplitude change (AAC) as defined in the reference above\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(np.diff(data, axis=1)), axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "\"\"\"Additional frequency domain features\"\"\"\n",
    "\n",
    "def spectral_centroid(data):\n",
    "    \"\"\"\n",
    "    Spectral Centroid\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Spectral centroid per channel (FFT-bin based)\n",
    "    \"\"\"\n",
    "    # Magnitude spectrum\n",
    "    spectrum = np.abs(np.fft.rfft(data, axis=1))\n",
    "    \n",
    "    # Frequency bin indices\n",
    "    freqs = np.arange(spectrum.shape[1])\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    denom = np.sum(spectrum, axis=1) + 1e-12\n",
    "    \n",
    "    centroid = np.sum(spectrum * freqs, axis=1) / denom\n",
    "    return centroid.reshape((1, data.shape[0]))\n",
    "\n",
    "\n",
    "def spectral_spread(data):\n",
    "    \"\"\"\n",
    "    Spectral Spread\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Spectral spread per channel (FFT-bin based)\n",
    "    \"\"\"\n",
    "    # Magnitude spectrum\n",
    "    spectrum = np.abs(np.fft.rfft(data, axis=1))\n",
    "    \n",
    "    # Frequency bin indices\n",
    "    freqs = np.arange(spectrum.shape[1])\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    denom = np.sum(spectrum, axis=1) + 1e-12\n",
    "    \n",
    "    # Spectral centroid\n",
    "    centroid = np.sum(spectrum * freqs, axis=1) / denom\n",
    "    \n",
    "    # Spectral spread (standard deviation around centroid)\n",
    "    spread = np.sqrt(\n",
    "        np.sum(spectrum * (freqs - centroid[:, None])**2, axis=1) / denom\n",
    "    )\n",
    "    \n",
    "    return spread.reshape((1, data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be139164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find labels for file detop_exp01_subj02_Sess3_02_02.pkl\n",
      "Movement: ['index_flex'] | Speed: ['fast']\n",
      "Could not find labels for file detop_exp01_subj03_Sess3_07_04.pkl\n",
      "Movement: ['cilinder'] | Speed: ['fast']\n",
      "Could not find labels for file detop_exp01_subj04_Sess2_11_02.pkl\n",
      "Movement: ['pinch'] | Speed: ['slow']\n",
      "Could not find labels for file detop_exp01_subj04_Sess1_03_05.pkl\n",
      "Movement: ['point'] | Speed: ['slow']\n",
      "Could not find labels for file detop_exp01_subj04_Sess1_05_06.pkl\n",
      "Movement: ['3digit'] | Speed: ['fast']\n",
      "Start time was less than end time for file detop_exp01_subj04_Sess1_05_01.pkl\n",
      "Start time: 1.8515625 | End time: 0.6796875\n",
      "Continuing to next file\n",
      "Start time was less than end time for file detop_exp01_subj10_Sess1_13_04.pkl\n",
      "Start time: 0.58984375 | End time: 0.0\n",
      "Continuing to next file\n",
      "Start time was less than end time for file detop_exp01_subj08_Sess2_08_05.pkl\n",
      "Start time: 4.17578125 | End time: 0.296875\n",
      "Continuing to next file\n",
      "Could not find labels for file detop_exp01_subj01_Sess2_13_01.pkl\n",
      "Movement: ['point'] | Speed: ['fast']\n",
      "Could not find labels for file detop_exp01_subj01_Sess1_12_06.pkl\n",
      "Movement: ['index_flex'] | Speed: ['fast']\n",
      "Could not find labels for file detop_exp01_subj01_Sess1_12_03.pkl\n",
      "Movement: ['index_flex'] | Speed: ['slow']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import resample, decimate\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "Create a dataset for classification training/testing.\n",
    "Each participant is stored in a separate file.\n",
    "\"\"\"\n",
    "\n",
    "def extract_windows_glove(data, num_windows, window_size, window_step):\n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        start = int(i*window_step)\n",
    "        end = int(start + window_size)\n",
    "        win_data = data[:, start:end]\n",
    "        win_data = np.mean(win_data, axis=1)\n",
    "        windows.append(win_data)\n",
    "    return np.array(windows)\n",
    "\n",
    "def extract_windows(data, num_windows, window_size, window_step):\n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        start = int(i*window_step)\n",
    "        end = int(start + window_size)\n",
    "        win_data = data[:, start:end]\n",
    "        windows.append(win_data)\n",
    "    return windows\n",
    "\n",
    "def num_windows(length, window_size, window_step):\n",
    "    return int(math.floor((length - window_size) / window_step)) + 1\n",
    "\n",
    "def extract_features_by_window(data, num_windows, window_size, window_step):\n",
    "    \"\"\"\n",
    "    Splits data set into windows, extracts features for each window\n",
    "    \"\"\"\n",
    "\n",
    "    feature_names = ['mav', 'var', 'rms', 'zcr', 'aac', 'sc', 'ss']\n",
    "\n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        start = int(i*window_step)\n",
    "        end = int(start + window_size)\n",
    "        win_data = data[:, start:end]\n",
    "\n",
    "        feature_array = []\n",
    "        feature_array.append(MAV(win_data))\n",
    "        feature_array.append(VAR(win_data))\n",
    "        feature_array.append(RMS(win_data))\n",
    "        feature_array.append(zero_crossings(win_data))\n",
    "        feature_array.append(avg_amplitude_change(win_data))\n",
    "        feature_array.append(spectral_centroid(win_data))\n",
    "        feature_array.append(spectral_spread(win_data))\n",
    "        \n",
    "        windows.append(feature_array)\n",
    "    return windows, feature_names\n",
    "\n",
    "\n",
    "# file handling\n",
    "ROOT = Path.cwd()\n",
    "LABELS = ROOT / 'labels'\n",
    "DATA = ROOT / 'pkl_dataset_resampled'\n",
    "\n",
    "# windowing\n",
    "FS = 512\n",
    "WINDOW_SIZE = int(0.2*FS)   # 200 ms windows\n",
    "WINDOW_HOP = WINDOW_SIZE // 2 # 50% overlap (NOTE: WINDOW_HOP = WINDOW_SIZE - WINDOW_OVERLAP)\n",
    "\n",
    "## Load labels data\n",
    "labels = pd.read_csv(LABELS / 'labels.csv', index_col=False)\n",
    "kill_list = pd.read_csv(LABELS / 'kill_list.csv', index_col=False)\n",
    "kill_list = kill_list['file'].to_list()\n",
    "\n",
    "## Create empty data frame for all data\n",
    "dataset_columns = {'movement': [], 'joints': [], 'speed': [], 'subject': [], 'session': [], 'trial': [], 'windows_raw': [], 'windows_feature': []}\n",
    "df = pd.DataFrame(dataset_columns)\n",
    "\n",
    "## Load in dataset\n",
    "dirs = [entry.name for entry in os.scandir(DATA) if entry.is_dir()]\n",
    "for dir in dirs:\n",
    "    files = [x for x in os.listdir(DATA / dir) if '.pkl' in x]\n",
    "    for file in files:\n",
    "        # load data file\n",
    "        temp = pd.read_pickle(DATA / dir / file)\n",
    "\n",
    "        if temp['movement'] == 'disc' or temp['movement'] == 'thumbAdd' or temp['movement'] == 'middle' or temp['movement'] == 'index' or file in kill_list:\n",
    "            continue\n",
    "\n",
    "        temp_row = dataset_columns.copy()\n",
    "\n",
    "        # get labels\n",
    "        file_labs = labels.loc[labels['file'] == file].to_dict(orient='records') # note if this returns more than 1 row something is wrong\n",
    "        # print(file_labs)\n",
    "        try:\n",
    "            file_labs = file_labs[0]\n",
    "            try:\n",
    "                start_sample = int(file_labs['start'] * FS)\n",
    "                end_sample = int(file_labs['end'] * FS)\n",
    "                # print(f\"Start time: {start_sample / FS} | End time: {end_sample / FS}\")\n",
    "            except:\n",
    "                raise ValueError(f'Could not access start')\n",
    "        except:\n",
    "                print(f\"Could not find labels for file {file}\")\n",
    "                print(f\"Movement: {temp['movement']} | Speed: {temp['speed']}\")\n",
    "        \n",
    "        if end_sample < start_sample:\n",
    "            print(f\"Start time was less than end time for file {file}\")\n",
    "            print(f\"Start time: {start_sample / FS} | End time: {end_sample / FS}\")\n",
    "            print(\"Continuing to next file\")\n",
    "            continue\n",
    "\n",
    "        emg = temp['emg']\n",
    "        joints = temp['glove']\n",
    "\n",
    "        # extract windows\n",
    "        n_windows = num_windows(emg.shape[1], WINDOW_SIZE, WINDOW_HOP)\n",
    "        windows = extract_windows(emg, n_windows, WINDOW_SIZE, WINDOW_HOP)\n",
    "        joints = extract_windows_glove(joints, n_windows, WINDOW_SIZE, WINDOW_HOP)\n",
    "        feature_windows, feature_names = extract_features_by_window(emg, n_windows, WINDOW_SIZE, WINDOW_HOP)\n",
    "\n",
    "        ## append data to dataframe\n",
    "        temp_row['windows_raw'] = windows\n",
    "        temp_row['windows_feature'] = feature_windows\n",
    "        temp_row['joints'] = joints\n",
    "        temp_row['speed'] = str(temp['speed'][0])\n",
    "        temp_row['subject'] = str(temp['subject'][0])\n",
    "        temp_row['movement'] = str(temp['movement'][0])\n",
    "        temp_row['session'] = int(temp['session'][0][0])\n",
    "        temp_row['trial'] = int(str(file).split('.')[0].split('_')[-1])\n",
    "\n",
    "        df_the_dict = pd.DataFrame([temp_row])\n",
    "        df = pd.concat([df, df_the_dict], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('dataset_regression.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9362ced",
   "metadata": {},
   "source": [
    "# Joint angle regression starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63557a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Joint angles regression\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reshape_data_windows_regression(X, y):\n",
    "    \"\"\"\n",
    "    Converts:\n",
    "        X: recordings x windows x features x channels\n",
    "        y: recordings x windows x output_channels\n",
    "\n",
    "    To:\n",
    "        X_out: total_windows x (features * channels)\n",
    "        y_out: total_windows x output_channels\n",
    "    \"\"\"\n",
    "\n",
    "    X_list = list(X)\n",
    "    y_list = list(y)\n",
    "\n",
    "    X_windows = []\n",
    "    y_windows = []\n",
    "\n",
    "    for rec_idx, (rec_X, rec_y) in enumerate(zip(X_list, y_list)):\n",
    "        rec_X = np.asarray(rec_X)\n",
    "        rec_y = np.asarray(rec_y)\n",
    "\n",
    "        # Skip recordings with no windows\n",
    "        if rec_X.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Sanity check\n",
    "        if rec_X.shape[0] != rec_y.shape[0]:\n",
    "            raise ValueError(\n",
    "                f\"Window mismatch in recording {rec_idx}: \"\n",
    "                f\"X has {rec_X.shape[0]}, y has {rec_y.shape[0]}\"\n",
    "            )\n",
    "\n",
    "        for w in range(rec_X.shape[0]):\n",
    "            # Flatten features x channels → 938\n",
    "            X_windows.append(rec_X[w].reshape(-1))\n",
    "            y_windows.append(rec_y[w])  # shape: (18,)\n",
    "\n",
    "    X_out = np.asarray(X_windows)\n",
    "    y_out = np.asarray(y_windows)\n",
    "\n",
    "    return X_out, y_out\n",
    "\n",
    "\n",
    "dataset = pd.read_pickle('dataset_regression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db25d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 1/10: 2.48e-03\n",
      "  gamma 1/10: 4.98e-02\n",
      "0 of 4 cross validations\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# kernel ridge regression\u001b[39;00m\n\u001b[32m     55\u001b[39m model = KernelRidge(\n\u001b[32m     56\u001b[39m     alpha=alpha_i,\n\u001b[32m     57\u001b[39m     kernel=\u001b[33m'\u001b[39m\u001b[33mrbf\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     58\u001b[39m     gamma=gamma_j\n\u001b[32m     59\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m y_val_pred = model.predict(X_val)\n\u001b[32m     64\u001b[39m r2_vals.append(\n\u001b[32m     65\u001b[39m     r2_score(y_val, y_val_pred, multioutput=\u001b[33m'\u001b[39m\u001b[33muniform_average\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     66\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/kernel_ridge.py:208\u001b[39m, in \u001b[36mKernelRidge.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sample_weight, \u001b[38;5;28mfloat\u001b[39m):\n\u001b[32m    206\u001b[39m     sample_weight = _check_sample_weight(sample_weight, X)\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m K = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m alpha = np.atleast_1d(\u001b[38;5;28mself\u001b[39m.alpha)\n\u001b[32m    211\u001b[39m ravel = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/kernel_ridge.py:172\u001b[39m, in \u001b[36mKernelRidge._get_kernel\u001b[39m\u001b[34m(self, X, Y)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    171\u001b[39m     params = {\u001b[33m\"\u001b[39m\u001b[33mgamma\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.gamma, \u001b[33m\"\u001b[39m\u001b[33mdegree\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.degree, \u001b[33m\"\u001b[39m\u001b[33mcoef0\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.coef0}\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpairwise_kernels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_params\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:2672\u001b[39m, in \u001b[36mpairwise_kernels\u001b[39m\u001b[34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[39m\n\u001b[32m   2669\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(metric):\n\u001b[32m   2670\u001b[39m     func = partial(_pairwise_callable, metric=metric, **kwds)\n\u001b[32m-> \u001b[39m\u001b[32m2672\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1969\u001b[39m, in \u001b[36m_parallel_pairwise\u001b[39m\u001b[34m(X, Y, func, n_jobs, **kwds)\u001b[39m\n\u001b[32m   1966\u001b[39m     Y = X\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) == \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1969\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[32m   1972\u001b[39m fd = delayed(_transposed_dist_wrapper)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1612\u001b[39m, in \u001b[36mrbf_kernel\u001b[39m\u001b[34m(X, Y, gamma)\u001b[39m\n\u001b[32m   1609\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gamma \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1610\u001b[39m     gamma = \u001b[32m1.0\u001b[39m / X.shape[\u001b[32m1\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1612\u001b[39m K = \u001b[43meuclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1613\u001b[39m K *= -gamma\n\u001b[32m   1614\u001b[39m \u001b[38;5;66;03m# exponentiate K in-place when using numpy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:371\u001b[39m, in \u001b[36meuclidean_distances\u001b[39m\u001b[34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[39m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared.shape != (\u001b[32m1\u001b[39m, Y.shape[\u001b[32m0\u001b[39m]):\n\u001b[32m    366\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    367\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    368\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:411\u001b[39m, in \u001b[36m_euclidean_distances\u001b[39m\u001b[34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[39m\n\u001b[32m    408\u001b[39m     distances += XX\n\u001b[32m    409\u001b[39m     distances += YY\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m xp_zero = \u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m distances = _modify_in_place_if_numpy(\n\u001b[32m    413\u001b[39m     xp, xp.maximum, distances, xp_zero, out=distances\n\u001b[32m    414\u001b[39m )\n\u001b[32m    416\u001b[39m \u001b[38;5;66;03m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# This may not be the case due to floating point rounding errors.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/sklearn/externals/array_api_compat/numpy/_aliases.py:89\u001b[39m, in \u001b[36masarray\u001b[39m\u001b[34m(obj, dtype, device, copy, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# asarray also adds the copy keyword, which is not present in numpy 1.0.\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# asarray() is different enough between numpy, cupy, and dask, the logic\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# complicated enough that it's easier to define it separately for each module\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# rather than trying to combine everything into one function in common/\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masarray\u001b[39m(\n\u001b[32m     90\u001b[39m     obj: Array | \u001b[38;5;28mcomplex\u001b[39m | NestedSequence[\u001b[38;5;28mcomplex\u001b[39m] | SupportsBufferProtocol,\n\u001b[32m     91\u001b[39m     /,\n\u001b[32m     92\u001b[39m     *,\n\u001b[32m     93\u001b[39m     dtype: DType | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     94\u001b[39m     device: Device | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     95\u001b[39m     copy: _Copy | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     96\u001b[39m     **kwargs: Any,\n\u001b[32m     97\u001b[39m ) -> Array:\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    Array API compatibility wrapper for asarray().\u001b[39;00m\n\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[33;03m    See the corresponding documentation in the array library and/or the array API\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m    specification for more details.\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    104\u001b[39m     _helpers._check_device(np, device)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.stats import bootstrap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# reshape\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['windows_feature'], dataset['joints'], test_size=0.2, random_state=42)\n",
    "X_train, y_train = reshape_data_windows_regression(X_train, y_train)\n",
    "\n",
    "# hyperparameters\n",
    "n = 10\n",
    "alphas = np.exp(np.linspace(-4, 4, n))  # literature-backed range\n",
    "\n",
    "r2_val_arr = []\n",
    "r2_train_arr = []\n",
    "ci_lows = np.zeros(n)\n",
    "ci_highs = np.zeros(n)\n",
    "\n",
    "for j, alpha_j in enumerate(alphas):\n",
    "    print(f'alpha: {alpha_j:.3e}   ({j+1}/{len(alphas)})')\n",
    "    \n",
    "    r2_val = []\n",
    "    r2_train = []\n",
    "    \n",
    "    for i in range(10):  # 10-fold CV\n",
    "        print(f'  Fold {i+1}/10')\n",
    "\n",
    "        # 50/50 split\n",
    "        X_train_i, X_val_i, y_train_i, y_val_i = train_test_split(\n",
    "            X_train, y_train,\n",
    "            test_size=0.5,\n",
    "            shuffle=True,\n",
    "            random_state=i\n",
    "        )\n",
    "\n",
    "        # PCA\n",
    "        pca = PCA()\n",
    "        X_train_i = pca.fit_transform(X_train_i)[:, :40]\n",
    "        X_val_i   = pca.transform(X_val_i)[:, :40]\n",
    "\n",
    "        # Scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_i   = scaler.transform(X_val_i)\n",
    "\n",
    "        # Ridge regression (multi-output by default)\n",
    "        reg = Ridge(alpha=alpha_j)\n",
    "        reg.fit(X_train_i, y_train_i)\n",
    "\n",
    "        # Predictions\n",
    "        y_val_pred = reg.predict(X_val_i)\n",
    "        y_train_pred = reg.predict(X_train_i)\n",
    "\n",
    "        # R² (average across outputs)\n",
    "        r2_val.append(\n",
    "            r2_score(y_val_i, y_val_pred, multioutput='uniform_average')\n",
    "        )\n",
    "        r2_train.append(\n",
    "            r2_score(y_train_i, y_train_pred, multioutput='uniform_average')\n",
    "        )\n",
    "\n",
    "        print(f'    Val R²: {r2_val[-1]:.3f}')\n",
    "        print(f'    Train R²: {r2_train[-1]:.3f}')\n",
    "\n",
    "    # Store means\n",
    "    r2_val_arr.append(np.mean(r2_val))\n",
    "    r2_train_arr.append(np.mean(r2_train))\n",
    "\n",
    "    # Confidence intervals (bootstrap)\n",
    "    ci_lows[j], ci_highs[j] = bootstrap(\n",
    "        (np.array(r2_val),),\n",
    "        np.mean\n",
    "    ).confidence_interval\n",
    "\n",
    "best_idx = np.argmax(r2_val_arr)\n",
    "best_alpha = alphas[best_idx]\n",
    "best_r2 = r2_val_arr[best_idx]\n",
    "\n",
    "plt.semilogx(alphas, r2_val_arr, label='validation')\n",
    "plt.semilogx(alphas, r2_train_arr, label='training')\n",
    "plt.plot(best_alpha, best_r2, 'ro')\n",
    "plt.fill_between(alphas, ci_lows, ci_highs, alpha=0.4)\n",
    "plt.legend()\n",
    "plt.xlabel('Regularization parameter α')\n",
    "plt.ylabel('R²')\n",
    "plt.title('Ridge Regression: R² vs α')\n",
    "plt.show()\n",
    "\n",
    "print(f'Optimal alpha: {best_alpha:.3e}')\n",
    "print(f'Best validation R²: {best_r2:.3f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
