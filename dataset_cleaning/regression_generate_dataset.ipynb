{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3877e8c1",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "This project is for making a linear regression model for joint angle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e316019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import resample, decimate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d769f41",
   "metadata": {},
   "source": [
    "The dataset needs to be restructured for linear regression.\n",
    "We don't need the gesture labels anymore, since our target is just joint angles.\n",
    "We need to window the joint angles too. For simplicity we will average the 200ms window of joint angle data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43368b",
   "metadata": {},
   "source": [
    "# Dataset export to get glove kinematic target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209a31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Features (from SEED dataset)\n",
    "\"\"\"\n",
    "\n",
    "def MAV(data):\n",
    "    \"\"\"\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: MAV of the data\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(data), axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "def VAR(data):\n",
    "    \"\"\"\n",
    "    Variance\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Variance of the data\n",
    "    \"\"\"\n",
    "    return np.var(data, axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "def RMS(data):\n",
    "    \"\"\"\n",
    "    Root mean square\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: RMS per channel\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean(data**2, axis=1)).reshape((1, data.shape[0]))\n",
    "\n",
    "def zero_crossings(data):\n",
    "    \"\"\"\n",
    "    Number of zero crossings from each channel\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: number of zero crossings for each channel\n",
    "    \"\"\"\n",
    "    positive = data > 0\n",
    "    return np.sum(np.bitwise_xor(positive[:, 1:], positive[:, :-1]), axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "def avg_amplitude_change(data):\n",
    "    \"\"\"\n",
    "    https://www.sciencedirect.com/science/article/pii/S0957417412001200\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Average amplitude change (AAC) as defined in the reference above\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(np.diff(data, axis=1)), axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "\"\"\"Additional frequency domain features\"\"\"\n",
    "\n",
    "def spectral_centroid(data):\n",
    "    \"\"\"\n",
    "    Spectral Centroid\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Spectral centroid per channel (FFT-bin based)\n",
    "    \"\"\"\n",
    "    # Magnitude spectrum\n",
    "    spectrum = np.abs(np.fft.rfft(data, axis=1))\n",
    "    \n",
    "    # Frequency bin indices\n",
    "    freqs = np.arange(spectrum.shape[1])\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    denom = np.sum(spectrum, axis=1) + 1e-12\n",
    "    \n",
    "    centroid = np.sum(spectrum * freqs, axis=1) / denom\n",
    "    return centroid.reshape((1, data.shape[0]))\n",
    "\n",
    "\n",
    "def spectral_spread(data):\n",
    "    \"\"\"\n",
    "    Spectral Spread\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Spectral spread per channel (FFT-bin based)\n",
    "    \"\"\"\n",
    "    # Magnitude spectrum\n",
    "    spectrum = np.abs(np.fft.rfft(data, axis=1))\n",
    "    \n",
    "    # Frequency bin indices\n",
    "    freqs = np.arange(spectrum.shape[1])\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    denom = np.sum(spectrum, axis=1) + 1e-12\n",
    "    \n",
    "    # Spectral centroid\n",
    "    centroid = np.sum(spectrum * freqs, axis=1) / denom\n",
    "    \n",
    "    # Spectral spread (standard deviation around centroid)\n",
    "    spread = np.sqrt(\n",
    "        np.sum(spectrum * (freqs - centroid[:, None])**2, axis=1) / denom\n",
    "    )\n",
    "    \n",
    "    return spread.reshape((1, data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be139164",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Digital filter critical frequencies must be 0 < Wn < 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 148\u001b[39m\n\u001b[32m    145\u001b[39m emg = temp[\u001b[33m'\u001b[39m\u001b[33memg\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    146\u001b[39m joints = temp[\u001b[33m'\u001b[39m\u001b[33mglove\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m emg = \u001b[43mprocess_emg_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43memg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# extract windows\u001b[39;00m\n\u001b[32m    151\u001b[39m n_windows = num_windows(emg.shape[\u001b[32m1\u001b[39m], WINDOW_SIZE, WINDOW_HOP)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mprocess_emg_data\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     92\u001b[39m processed = np.zeros_like(emg)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(emg.shape[\u001b[32m0\u001b[39m]):\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     bp = \u001b[43mbandpass_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43memg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     notch = notch_filter(bp, FS)\n\u001b[32m     97\u001b[39m     rect = rectify(notch)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mbandpass_filter\u001b[39m\u001b[34m(signal, fs, lowcut, highcut, order)\u001b[39m\n\u001b[32m     73\u001b[39m low = lowcut / nyq\n\u001b[32m     74\u001b[39m high = highcut / nyq\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m b, a = \u001b[43mbutter\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbandpass\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m filtered = filtfilt(b, a, signal)\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m filtered\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/scipy/signal/_filter_design.py:3475\u001b[39m, in \u001b[36mbutter\u001b[39m\u001b[34m(N, Wn, btype, analog, output, fs)\u001b[39m\n\u001b[32m   3354\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbutter\u001b[39m(N, Wn, btype=\u001b[33m'\u001b[39m\u001b[33mlow\u001b[39m\u001b[33m'\u001b[39m, analog=\u001b[38;5;28;01mFalse\u001b[39;00m, output=\u001b[33m'\u001b[39m\u001b[33mba\u001b[39m\u001b[33m'\u001b[39m, fs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   3355\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3356\u001b[39m \u001b[33;03m    Butterworth digital and analog filter design.\u001b[39;00m\n\u001b[32m   3357\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3473\u001b[39m \u001b[33;03m    >>> plt.show()\u001b[39;00m\n\u001b[32m   3474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3475\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miirfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manalog\u001b[49m\u001b[43m=\u001b[49m\u001b[43manalog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3476\u001b[39m \u001b[43m                     \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mftype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbutter\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Gesture-Recognition/venv/lib/python3.11/site-packages/scipy/signal/_filter_design.py:2847\u001b[39m, in \u001b[36miirfilter\u001b[39m\u001b[34m(N, Wn, rp, rs, btype, analog, ftype, output, fs)\u001b[39m\n\u001b[32m   2844\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2845\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDigital filter critical frequencies must \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2846\u001b[39m                          \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbe 0 < Wn < fs/2 (fs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> fs/2=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfs/\u001b[32m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2847\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDigital filter critical frequencies \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2848\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33mmust be 0 < Wn < 1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2849\u001b[39m fs = \u001b[32m2.0\u001b[39m\n\u001b[32m   2850\u001b[39m warped = \u001b[32m2\u001b[39m * fs * tan(pi * Wn / fs)\n",
      "\u001b[31mValueError\u001b[39m: Digital filter critical frequencies must be 0 < Wn < 1"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import resample, decimate\n",
    "import os\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "\n",
    "\"\"\"\n",
    "Create a dataset for classification training/testing.\n",
    "Each participant is stored in a separate file.\n",
    "\"\"\"\n",
    "\n",
    "def extract_windows_glove(data, num_windows, window_size, window_step):\n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        start = int(i*window_step)\n",
    "        end = int(start + window_size)\n",
    "        win_data = data[:, start:end]\n",
    "        win_data = np.mean(win_data, axis=1)\n",
    "        windows.append(win_data)\n",
    "    return np.array(windows)\n",
    "\n",
    "def extract_windows(data, num_windows, window_size, window_step):\n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        start = int(i*window_step)\n",
    "        end = int(start + window_size)\n",
    "        win_data = data[:, start:end]\n",
    "        windows.append(win_data)\n",
    "    return windows\n",
    "\n",
    "def num_windows(length, window_size, window_step):\n",
    "    return int(math.floor((length - window_size) / window_step)) + 1\n",
    "\n",
    "def extract_features_by_window(data, num_windows, window_size, window_step):\n",
    "    \"\"\"\n",
    "    Splits data set into windows, extracts features for each window\n",
    "    \"\"\"\n",
    "\n",
    "    feature_names = ['mav', 'var', 'rms', 'zcr', 'aac', 'sc', 'ss']\n",
    "\n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        start = int(i*window_step)\n",
    "        end = int(start + window_size)\n",
    "        win_data = data[:, start:end]\n",
    "\n",
    "        feature_array = []\n",
    "        feature_array.append(MAV(win_data))\n",
    "        feature_array.append(VAR(win_data))\n",
    "        feature_array.append(RMS(win_data))\n",
    "        feature_array.append(zero_crossings(win_data))\n",
    "        feature_array.append(avg_amplitude_change(win_data))\n",
    "        feature_array.append(spectral_centroid(win_data))\n",
    "        feature_array.append(spectral_spread(win_data))\n",
    "        \n",
    "        windows.append(feature_array)\n",
    "    return windows, feature_names\n",
    "\n",
    "# file handling\n",
    "ROOT = Path.cwd()\n",
    "LABELS = ROOT / 'labels'\n",
    "DATA = ROOT / 'pkl_dataset_resampled'\n",
    "\n",
    "# windowing\n",
    "FS = 1024\n",
    "WINDOW_SIZE = int(0.2*FS)   # 200 ms windows\n",
    "WINDOW_HOP = WINDOW_SIZE // 2 # 50% overlap (NOTE: WINDOW_HOP = WINDOW_SIZE - WINDOW_OVERLAP)\n",
    "\n",
    "def bandpass_filter(signal, fs, lowcut=80, highcut=500, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "\n",
    "    b, a = butter(order, [low, high], btype='bandpass')\n",
    "    filtered = filtfilt(b, a, signal)\n",
    "    return filtered\n",
    "\n",
    "def notch_filter(signal, fs, freq=60, q=30):\n",
    "    nyq = 0.5 * fs\n",
    "    w0 = freq / nyq\n",
    "\n",
    "    b, a = iirnotch(w0, q)\n",
    "    filtered = filtfilt(b, a, signal)\n",
    "    return filtered\n",
    "\n",
    "def rectify(signal):\n",
    "    return np.abs(signal)\n",
    "\n",
    "def process_emg_data(data):\n",
    "    processed = np.zeros_like(emg)\n",
    "\n",
    "    for ch in range(emg.shape[0]):\n",
    "        bp = bandpass_filter(emg[ch, :], FS)\n",
    "        notch = notch_filter(bp, FS)\n",
    "        rect = rectify(notch)\n",
    "        processed[ch, :] = rect\n",
    "\n",
    "    return processed\n",
    "\n",
    "## Load labels data\n",
    "labels = pd.read_csv(LABELS / 'labels.csv', index_col=False)\n",
    "kill_list = pd.read_csv(LABELS / 'kill_list.csv', index_col=False)\n",
    "kill_list = kill_list['file'].to_list()\n",
    "\n",
    "## Create empty data frame for all data\n",
    "dataset_columns = {'movement': [], 'joints': [], 'speed': [], 'subject': [], 'session': [], 'trial': [], 'windows_raw': [], 'windows_feature': []}\n",
    "df = pd.DataFrame(dataset_columns)\n",
    "\n",
    "## Load in dataset\n",
    "dirs = [entry.name for entry in os.scandir(DATA) if entry.is_dir()]\n",
    "for dir in dirs:\n",
    "    files = [x for x in os.listdir(DATA / dir) if '.pkl' in x]\n",
    "    for file in files:\n",
    "        # load data file\n",
    "        temp = pd.read_pickle(DATA / dir / file)\n",
    "\n",
    "        if temp['movement'] == 'disc' or temp['movement'] == 'thumbAdd' or temp['movement'] == 'middle' or temp['movement'] == 'index' or file in kill_list:\n",
    "            continue\n",
    "\n",
    "        temp_row = dataset_columns.copy()\n",
    "\n",
    "        # get labels\n",
    "        file_labs = labels.loc[labels['file'] == file].to_dict(orient='records') # note if this returns more than 1 row something is wrong\n",
    "        # print(file_labs)\n",
    "        try:\n",
    "            file_labs = file_labs[0]\n",
    "            try:\n",
    "                start_sample = int(file_labs['start'] * FS)\n",
    "                end_sample = int(file_labs['end'] * FS)\n",
    "                # print(f\"Start time: {start_sample / FS} | End time: {end_sample / FS}\")\n",
    "            except:\n",
    "                raise ValueError(f'Could not access start')\n",
    "        except:\n",
    "                print(f\"Could not find labels for file {file}\")\n",
    "                print(f\"Movement: {temp['movement']} | Speed: {temp['speed']}\")\n",
    "        \n",
    "        if end_sample < start_sample:\n",
    "            print(f\"Start time was less than end time for file {file}\")\n",
    "            print(f\"Start time: {start_sample / FS} | End time: {end_sample / FS}\")\n",
    "            print(\"Continuing to next file\")\n",
    "            continue\n",
    "\n",
    "        emg = temp['emg']\n",
    "        joints = temp['glove']\n",
    "\n",
    "        emg = process_emg_data(emg)\n",
    "\n",
    "        # extract windows\n",
    "        n_windows = num_windows(emg.shape[1], WINDOW_SIZE, WINDOW_HOP)\n",
    "        windows = extract_windows(emg, n_windows, WINDOW_SIZE, WINDOW_HOP)\n",
    "        joints = extract_windows_glove(joints, n_windows, WINDOW_SIZE, WINDOW_HOP)\n",
    "        feature_windows, feature_names = extract_features_by_window(emg, n_windows, WINDOW_SIZE, WINDOW_HOP)\n",
    "\n",
    "        ## append data to dataframe\n",
    "        temp_row['windows_raw'] = windows\n",
    "        temp_row['windows_feature'] = feature_windows\n",
    "        temp_row['joints'] = joints\n",
    "        temp_row['speed'] = str(temp['speed'][0])\n",
    "        temp_row['subject'] = str(temp['subject'][0])\n",
    "        temp_row['movement'] = str(temp['movement'][0])\n",
    "        temp_row['session'] = int(temp['session'][0][0])\n",
    "        temp_row['trial'] = int(str(file).split('.')[0].split('_')[-1])\n",
    "\n",
    "        df_the_dict = pd.DataFrame([temp_row])\n",
    "        df = pd.concat([df, df_the_dict], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66cc3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('dataset_regression.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
