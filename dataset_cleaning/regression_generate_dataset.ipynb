{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3877e8c1",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "This project is for making a linear regression model for joint angle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e316019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import resample, decimate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d769f41",
   "metadata": {},
   "source": [
    "The dataset needs to be restructured for linear regression.\n",
    "We don't need the gesture labels anymore, since our target is just joint angles.\n",
    "We need to window the joint angles too. For simplicity we will average the 200ms window of joint angle data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43368b",
   "metadata": {},
   "source": [
    "# Dataset export to get glove kinematic target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209a31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Features (from SEED dataset)\n",
    "\"\"\"\n",
    "\n",
    "def MAV(data):\n",
    "    \"\"\"\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: MAV of the data\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(data), axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "def VAR(data):\n",
    "    \"\"\"\n",
    "    Variance\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Variance of the data\n",
    "    \"\"\"\n",
    "    return np.var(data, axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "def RMS(data):\n",
    "    \"\"\"\n",
    "    Root mean square\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: RMS per channel\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean(data**2, axis=1)).reshape((1, data.shape[0]))\n",
    "\n",
    "def zero_crossings(data):\n",
    "    \"\"\"\n",
    "    Number of zero crossings from each channel\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: number of zero crossings for each channel\n",
    "    \"\"\"\n",
    "    positive = data > 0\n",
    "    return np.sum(np.bitwise_xor(positive[:, 1:], positive[:, :-1]), axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "def avg_amplitude_change(data):\n",
    "    \"\"\"\n",
    "    https://www.sciencedirect.com/science/article/pii/S0957417412001200\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Average amplitude change (AAC) as defined in the reference above\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(np.diff(data, axis=1)), axis=1).reshape((1, data.shape[0]))\n",
    "\n",
    "\"\"\"Additional frequency domain features\"\"\"\n",
    "\n",
    "def spectral_centroid(data):\n",
    "    \"\"\"\n",
    "    Spectral Centroid\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Spectral centroid per channel (FFT-bin based)\n",
    "    \"\"\"\n",
    "    # Magnitude spectrum\n",
    "    spectrum = np.abs(np.fft.rfft(data, axis=1))\n",
    "    \n",
    "    # Frequency bin indices\n",
    "    freqs = np.arange(spectrum.shape[1])\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    denom = np.sum(spectrum, axis=1) + 1e-12\n",
    "    \n",
    "    centroid = np.sum(spectrum * freqs, axis=1) / denom\n",
    "    return centroid.reshape((1, data.shape[0]))\n",
    "\n",
    "\n",
    "def spectral_spread(data):\n",
    "    \"\"\"\n",
    "    Spectral Spread\n",
    "    :param data: 2D array, channels x samples\n",
    "    :return: Spectral spread per channel (FFT-bin based)\n",
    "    \"\"\"\n",
    "    # Magnitude spectrum\n",
    "    spectrum = np.abs(np.fft.rfft(data, axis=1))\n",
    "    \n",
    "    # Frequency bin indices\n",
    "    freqs = np.arange(spectrum.shape[1])\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    denom = np.sum(spectrum, axis=1) + 1e-12\n",
    "    \n",
    "    # Spectral centroid\n",
    "    centroid = np.sum(spectrum * freqs, axis=1) / denom\n",
    "    \n",
    "    # Spectral spread (standard deviation around centroid)\n",
    "    spread = np.sqrt(\n",
    "        np.sum(spectrum * (freqs - centroid[:, None])**2, axis=1) / denom\n",
    "    )\n",
    "    \n",
    "    return spread.reshape((1, data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be139164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time was less than end time for file detop_exp01_subj10_Sess1_13_04.pkl\n",
      "Start time: 0.58984375 | End time: 0.0\n",
      "Continuing to next file\n",
      "Could not find labels for file detop_exp01_subj03_Sess3_07_04.pkl\n",
      "Movement: ['cilinder'] | Speed: ['fast']\n",
      "Start time was less than end time for file detop_exp01_subj04_Sess1_05_01.pkl\n",
      "Start time: 1.8515625 | End time: 0.6806640625\n",
      "Continuing to next file\n",
      "Could not find labels for file detop_exp01_subj04_Sess1_03_05.pkl\n",
      "Movement: ['point'] | Speed: ['slow']\n",
      "Could not find labels for file detop_exp01_subj04_Sess2_11_02.pkl\n",
      "Movement: ['pinch'] | Speed: ['slow']\n",
      "Could not find labels for file detop_exp01_subj04_Sess1_05_06.pkl\n",
      "Movement: ['3digit'] | Speed: ['fast']\n",
      "Could not find labels for file detop_exp01_subj02_Sess3_02_02.pkl\n",
      "Movement: ['index_flex'] | Speed: ['fast']\n",
      "Could not find labels for file detop_exp01_subj01_Sess2_13_01.pkl\n",
      "Movement: ['point'] | Speed: ['fast']\n",
      "Could not find labels for file detop_exp01_subj01_Sess1_12_06.pkl\n",
      "Movement: ['index_flex'] | Speed: ['fast']\n",
      "Could not find labels for file detop_exp01_subj01_Sess1_12_03.pkl\n",
      "Movement: ['index_flex'] | Speed: ['slow']\n",
      "Start time was less than end time for file detop_exp01_subj08_Sess2_08_05.pkl\n",
      "Start time: 4.17578125 | End time: 0.296875\n",
      "Continuing to next file\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import resample, decimate\n",
    "import os\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "\n",
    "\"\"\"\n",
    "Create a dataset for classification training/testing.\n",
    "Each participant is stored in a separate file.\n",
    "\"\"\"\n",
    "\n",
    "def extract_windows_glove(data, num_windows, window_size, window_step):\n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        start = int(i*window_step)\n",
    "        end = int(start + window_size)\n",
    "        win_data = data[:, start:end]\n",
    "        win_data = np.mean(win_data, axis=1)\n",
    "        windows.append(win_data)\n",
    "    return np.array(windows)\n",
    "\n",
    "def extract_windows(data, num_windows, window_size, window_step):\n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        start = int(i*window_step)\n",
    "        end = int(start + window_size)\n",
    "        win_data = data[:, start:end]\n",
    "        windows.append(win_data)\n",
    "    return windows\n",
    "\n",
    "def num_windows(length, window_size, window_step):\n",
    "    return int(math.floor((length - window_size) / window_step)) + 1\n",
    "\n",
    "def extract_features_by_window(data, num_windows, window_size, window_step):\n",
    "    \"\"\"\n",
    "    Splits data set into windows, extracts features for each window\n",
    "    \"\"\"\n",
    "\n",
    "    feature_names = ['mav', 'var', 'rms', 'zcr', 'aac', 'sc', 'ss']\n",
    "\n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        start = int(i*window_step)\n",
    "        end = int(start + window_size)\n",
    "        win_data = data[:, start:end]\n",
    "\n",
    "        feature_array = []\n",
    "        feature_array.append(MAV(win_data))\n",
    "        feature_array.append(VAR(win_data))\n",
    "        feature_array.append(RMS(win_data))\n",
    "        feature_array.append(zero_crossings(win_data))\n",
    "        feature_array.append(avg_amplitude_change(win_data))\n",
    "        feature_array.append(spectral_centroid(win_data))\n",
    "        feature_array.append(spectral_spread(win_data))\n",
    "        \n",
    "        windows.append(feature_array)\n",
    "    return windows, feature_names\n",
    "\n",
    "# file handling\n",
    "ROOT = Path.cwd()\n",
    "LABELS = ROOT / 'labels'\n",
    "DATA = ROOT / 'pkl_dataset_resampled'\n",
    "\n",
    "# windowing\n",
    "FS = 1024\n",
    "WINDOW_SIZE = int(0.2*FS)   # 200 ms windows\n",
    "WINDOW_HOP = WINDOW_SIZE // 2 # 50% overlap (NOTE: WINDOW_HOP = WINDOW_SIZE - WINDOW_OVERLAP)\n",
    "\n",
    "def bandpass_filter(signal, fs, lowcut=80, highcut=500, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "\n",
    "    b, a = butter(order, [low, high], btype='bandpass')\n",
    "    filtered = filtfilt(b, a, signal)\n",
    "    return filtered\n",
    "\n",
    "def notch_filter(signal, fs, freq=60, q=30):\n",
    "    nyq = 0.5 * fs\n",
    "    w0 = freq / nyq\n",
    "\n",
    "    b, a = iirnotch(w0, q)\n",
    "    filtered = filtfilt(b, a, signal)\n",
    "    return filtered\n",
    "\n",
    "def rectify(signal):\n",
    "    return np.abs(signal)\n",
    "\n",
    "def process_emg_data(data):\n",
    "    processed = np.zeros_like(emg)\n",
    "\n",
    "    for ch in range(emg.shape[0]):\n",
    "        bp = bandpass_filter(emg[ch, :], FS)\n",
    "        #notch = notch_filter(bp, FS)\n",
    "        rect = rectify(bp)\n",
    "        processed[ch, :] = rect\n",
    "\n",
    "    return processed\n",
    "\n",
    "## Load labels data\n",
    "labels = pd.read_csv(LABELS / 'labels.csv', index_col=False)\n",
    "kill_list = pd.read_csv(LABELS / 'kill_list.csv', index_col=False)\n",
    "kill_list = kill_list['file'].to_list()\n",
    "\n",
    "## Create empty data frame for all data\n",
    "dataset_columns = {'movement': [], 'joints': [], 'speed': [], 'subject': [], 'session': [], 'trial': [], 'windows_raw': [], 'windows_feature': []}\n",
    "df = pd.DataFrame(dataset_columns)\n",
    "\n",
    "## Load in dataset\n",
    "dirs = [entry.name for entry in os.scandir(DATA) if entry.is_dir()]\n",
    "for dir in dirs:\n",
    "    files = [x for x in os.listdir(DATA / dir) if '.pkl' in x]\n",
    "    for file in files:\n",
    "        # load data file\n",
    "        temp = pd.read_pickle(DATA / dir / file)\n",
    "\n",
    "        if temp['movement'] == 'disc' or temp['movement'] == 'thumbAdd' or temp['movement'] == 'middle' or temp['movement'] == 'index' or file in kill_list:\n",
    "            continue\n",
    "\n",
    "        temp_row = dataset_columns.copy()\n",
    "\n",
    "        # get labels\n",
    "        file_labs = labels.loc[labels['file'] == file].to_dict(orient='records') # note if this returns more than 1 row something is wrong\n",
    "        # print(file_labs)\n",
    "        try:\n",
    "            file_labs = file_labs[0]\n",
    "            try:\n",
    "                start_sample = int(file_labs['start'] * FS)\n",
    "                end_sample = int(file_labs['end'] * FS)\n",
    "                # print(f\"Start time: {start_sample / FS} | End time: {end_sample / FS}\")\n",
    "            except:\n",
    "                raise ValueError(f'Could not access start')\n",
    "        except:\n",
    "                print(f\"Could not find labels for file {file}\")\n",
    "                print(f\"Movement: {temp['movement']} | Speed: {temp['speed']}\")\n",
    "        \n",
    "        if end_sample < start_sample:\n",
    "            print(f\"Start time was less than end time for file {file}\")\n",
    "            print(f\"Start time: {start_sample / FS} | End time: {end_sample / FS}\")\n",
    "            print(\"Continuing to next file\")\n",
    "            continue\n",
    "\n",
    "        emg = temp['emg']\n",
    "        joints = temp['glove']\n",
    "\n",
    "        # extract windows\n",
    "        n_windows = num_windows(emg.shape[1], WINDOW_SIZE, WINDOW_HOP)\n",
    "        windows = extract_windows(emg, n_windows, WINDOW_SIZE, WINDOW_HOP)\n",
    "        joints = extract_windows_glove(joints, n_windows, WINDOW_SIZE, WINDOW_HOP)\n",
    "        feature_windows, feature_names = extract_features_by_window(emg, n_windows, WINDOW_SIZE, WINDOW_HOP)\n",
    "\n",
    "        ## append data to dataframe\n",
    "        temp_row['windows_raw'] = windows\n",
    "        temp_row['windows_feature'] = feature_windows\n",
    "        temp_row['joints'] = joints\n",
    "        temp_row['speed'] = str(temp['speed'][0])\n",
    "        temp_row['subject'] = str(temp['subject'][0])\n",
    "        temp_row['movement'] = str(temp['movement'][0])\n",
    "        temp_row['session'] = int(temp['session'][0][0])\n",
    "        temp_row['trial'] = int(str(file).split('.')[0].split('_')[-1])\n",
    "\n",
    "        df_the_dict = pd.DataFrame([temp_row])\n",
    "        df = pd.concat([df, df_the_dict], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66cc3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('dataset_regression.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gesture-recognition-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
